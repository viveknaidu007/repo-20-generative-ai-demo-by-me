{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "mykey = \"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\"\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero shot prompting\n",
    "prompt = \"can you tell me total no of country in asia? can you give me you top 10 country name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 countries in Asia.\n",
      "\n",
      "Top 10 countries in Asia are:\n",
      "\n",
      "1. China\n",
      "2. India\n",
      "3. Japan\n",
      "4. Indonesia\n",
      "5. Pakistan\n",
      "6. Bangladesh\n",
      "7. Russia\n",
      "8. Philippines\n",
      "9. Vietnam\n",
      "10. Iran\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"can u tell me capital of india\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt2).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"what exactly tokens, vector?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens are individual units of text, typically separated by spaces or punctuation marks. They can be words, numbers, symbols, or other elements that make up a larger piece of text.\n",
      "\n",
      "A vector is a mathematical concept that represents a quantity with both magnitude and direction. In the context of natural language processing, a vector is often used to represent the meaning or semantic relationships between words or phrases. Each dimension of the vector may correspond to a different aspect of meaning, such as frequency, context, or sentiment. Vectors are commonly used in machine learning algorithms for tasks such as text classification and language translation.\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt3).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"country\"],\n",
    "    template = \"can you tell me the capital of {country}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = prompt_template_name.format(country=\"indai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt_template_name.format(country=\"china\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of China is Beijing.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langchain givinf the 2 options for promps like this method also\n",
    "prompt = PromptTemplate.from_template('what is the good name for a company tha makes a {product}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = prompt.format(product=\"toys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Playtopia\" or \"Toytopia\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent , whicb will extract teh informatio from the 3rd party api\n",
    "#who i a agent ? lol lets see in real life , u want to buy a product in company , there are agents who are ready to exlain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"can you tell me who won the recent cricket world cup?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The recent cricket world cup was won by England in 2019.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt4).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5 = \"can yoou tell me current gdp of india?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2021, the current GDP of India is approximately $2.7 trillion USD. However, due to the ongoing COVID-19 pandemic and its impact on the economy, this number is constantly changing.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt5).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see our model learned till 2019.\n",
    "#now im usiing the \"AGENT\"\n",
    "\n",
    "#for extracting real time info i am going to user serp api\n",
    "\n",
    "#now by using this serp api i will call google-search-engine \n",
    "#and i will extract the informationiin real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests->google-search-results) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests->google-search-results) (2023.11.17)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=44a83c99f06b63db7a614e384c53b39e751b8c7f0a4abd3f2943d5590190daa8\n",
      "  Stored in directory: c:\\users\\poppo\\appdata\\local\\pip\\cache\\wheels\\29\\75\\71\\9bf68178a74593837f73b6e9d9a070d45d308bddfd2e95290a\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_key = \"d56d3d6a96e4f106a86c032027c21c2350ec1e5ce04c7e4459de98c5d2322101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"serpapi\"], serpapi_api_key=serpapi_key,llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tool, client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Australia won the recent World Cup Cricket.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"who won recent world cup cricket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current date is Thursday, February 1, 2024.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"today date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11704 sha256=b6d8cfeb590e7e101c920405c0d07c5a7148f931171a9a86e8c08e13814521f9\n",
      "  Stored in directory: c:\\users\\poppo\\appdata\\local\\pip\\cache\\wheels\\07\\93\\05\\72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"wikipedia\"], llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tool, client,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to search for information on recent movies about Animal.\n",
      "Action: Wikipedia\n",
      "Action Input: Recent movies about Animal\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Animal House\n",
      "Summary: National Lampoon's Animal House is a 1978 American comedy film directed by John Landis and written by Harold Ramis, Douglas Kenney and Chris Miller. It stars John Belushi, Tim Matheson, John Vernon, Verna Bloom, Thomas Hulce and Donald Sutherland. The film is about a trouble-making fraternity whose members challenge the authority of the dean of the fictional Faber College.\n",
      "Produced by Matty Simmons of National Lampoon and Ivan Reitman for Universal Pictures, it was inspired by stories written by Miller and published in National Lampoon, which were based on Ramis' experience in the Zeta Beta Tau fraternity at Washington University in St. Louis, Miller's Alpha Delta Phi experiences at Dartmouth College in New Hampshire, and producer Reitman's at McMaster University in Hamilton, Ontario.\n",
      "Of the younger lead actors, only the 28-year-old Belushi was an established star, but even he had not yet appeared in a film, having gained fame as an original cast member of Saturday Night Live, which was in its third season in the autumn of 1977. Several of the actors who were cast as college students, including Thomas Hulce, Karen Allen, and Kevin Bacon, were just beginning their film careers. Matheson, also cast as a student, was already a seasoned actor, having appeared in movies and television since the age of 13.\n",
      "Filming took place at the University of Oregon from October to December 1977. Following its initial release on July 28, 1978, Animal House received generally mixed reviews from critics, but Time and Roger Ebert proclaimed it one of the year's best. Filmed for only $3 million (equivalent to $13,460,204 in today's money) it garnered an estimated gross of more than $141 million ($632,629,592 in today's money) in the form of theatrical rentals and home video, not including merchandising, making it the highest grossing comedy film of its time.The film, along with 1977's The Kentucky Fried Movie, also directed by Landis, was largely responsible for defining and launching the gross out film genre, which became one of Hollywood's staples. Animal House is now regarded as one of the best comedy films of all time.In 2001, the United States Library of Congress deemed National Lampoon's Animal House \"culturally, historically, or aesthetically significant\" and selected it for preservation in the National Film Registry. It was No. 1 on Bravo's \"100 Funniest Movies\". It was No. 36 on AFI's \"100 Years... 100 Laughs\" list of the 100 best American comedies. In 2008, Empire magazine selected it as No. 279 of \"The 500 Greatest Movies of All Time\".\n",
      "\n",
      "Page: Animal\n",
      "Summary: Animals are multicellular, eukaryotic organisms in the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, have myocytes and are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Animals form a single clade.\n",
      "As of 2022, around 2.16 million living animal species have been described‚Äîof which around 1.05 million are insects, over 85,000 are molluscs, and around 65,000 are vertebrates. It has been estimated there are as many as 7.77 million animal species on Earth. Animals' body lengths range from 8.5 Œºm (0.00033 in) to 33.6 m (110 ft). They have complex ecologies and interactions with each other and their environments, forming intricate food webs. The scientific study of animals is known as zoology, and the study of animal behaviors is known as ethology.\n",
      "Most living animal species belong to the infrakingdom Bilateria, a highly proliferative clade whose members have a bilaterally symmetric body plan. Extant bilaterians include the basal group Xenacoelomorpha, but the vast majority belong to two large superphyla: the protostomes, which include phyla such as arthropods, molluscs, flatworms, annelids and nematodes, etc.; and the deuterostomes, which include the three phyla echinoderms, hemichordates and chordates, the latter with the vertebrates b\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The recent movie about Animal is most likely referring to National Lampoon's Animal House, a 1978 comedy film. If not, it could be referring to the biological kingdom Animalia, which includes over 2 million living species. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The recent movie about Animal is most likely referring to National Lampoon's Animal House, a 1978 comedy film. If not, it could be referring to the biological kingdom Animalia, which includes over 2 million living species.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"can you tell me about the recent movie about Animal?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to LangChain is a vital component known as LangChain Chains, forming the core connection among one or several large language models (LLMs). In certain sophisticated applications, it becomes necessary to chain LLMs together, either with each other or with other elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "mykey = \"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\"\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x16e452d8820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt1=PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chain\u001b[38;5;241m=\u001b[39m\u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "mykey = \"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\"\n",
    "client = OpenAI(openai_api_key=mykey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt1=PromptTemplate.from_template(\"what is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=client,prompt=prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Vineyard Vines\\n2. Grapevine Wines\\n3. Vintage Vintners\\n4. Cellar Selections\\n5. Bacchus Winery\\n6. Harvest Hill Wines\\n7. Redwood Ridge Winery\\n8. Chateau Chardonnay\\n9. Noble Nectar Wines\\n10. Sip & Savor Winery'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"wine\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"i want to open a restaurent for {cuisine} food, suggest a fency name for this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['cuisine'], template='i want to open a restaurent for {cuisine} food, suggest a fency name for this')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Imperial Dragon Palace\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"chinese\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=client, prompt=prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mi want to open a restaurent for american food, suggest a fency name for this\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"The Stateside Bistro\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"american\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we want to combine multiple chain and set a sequence for that we use simplesequencialchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "input_variables=[\"startup_name\"],\n",
    "    template=\"I want to start a startup for {startup-name} , suggest me a good name for this\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain=LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items=PromptTemplate(\n",
    "input_variables=[\"name\"],\n",
    "    template=\"suggest some strategies for {name}\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain=LLMChain(llm=client,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Develop a strong online presence: Create a professional website and maintain active social media accounts to showcase your services and reach potential clients.\n",
      "\n",
      "2. Network and collaborate: Attend industry events, join professional organizations, and network with other businesses and individuals in your field. Collaborating with others can help expand your reach and bring in new clients.\n",
      "\n",
      "3. Offer free consultations or trials: Give potential clients a taste of your services by offering free consultations or trials. This can help build trust and showcase your expertise.\n",
      "\n",
      "4. Utilize targeted advertising: Use targeted advertising on platforms like Google AdWords and social media to reach your target audience. This can help bring in more qualified leads.\n",
      "\n",
      "5. Leverage customer testimonials: Encourage satisfied clients to leave reviews and testimonials on your website and social media pages. Positive reviews can be a powerful marketing tool.\n",
      "\n",
      "6. Develop a referral program: Create a referral program to incentivize current clients to refer new business to you. This can be in the form of discounts, free services, or other rewards.\n",
      "\n",
      "7. Partner with complementary businesses: Identify businesses that offer complementary services and partner with them to cross-promote each other's services. This can help expand your reach and bring in new clients.\n",
      "\n",
      "8. Offer educational resources: Share your knowledge and expertise\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"artifical intelligence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try to understand the sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    template=\"i want to open a restaurant for {cuisine}, suggest a fency name for it\"\n",
    ")\n",
    "\n",
    "name_chain=LLMChain(llm=client, prompt=prompt_template_name,output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates_items=PromptTemplate( \n",
    "    input_variables=[\"restaurant_name\"],\n",
    "    template=\"suggest some menu items for {restaurant_name}\"\n",
    "    \n",
    ")\n",
    "\n",
    "food_items_chain=LLMChain(llm=client, prompt=prompt_templates_items, output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=SequentialChain(chains=[name_chain, food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Affair\"',\n",
       " 'menu_items': '\\n\\n1. Spicy Chicken Tikka Masala\\n2. Aloo Gobi (potatoes and cauliflower in spicy curry)\\n3. Lamb Vindaloo (spicy lamb curry)\\n4. Tandoori Shrimp Skewers\\n5. Vegetable Samosas\\n6. Chana Masala (spicy chickpea curry)\\n7. Butter Chicken\\n8. Spicy Chicken Biryani\\n9. Masala Dosa (spicy crepe filled with potatoes and onions)\\n10. Tandoori Paneer Tikka (spicy grilled cheese cubes)\\n11. Chicken Korma (spicy chicken in creamy tomato sauce)\\n12. Baingan Bharta (spicy eggplant curry)\\n13. Mango Lassi (yogurt-based drink to cool down the spice)\\n14. Garlic Naan (spicy garlic flatbread)\\n15. Gulab Jamun (spicy sweet milk balls in syrup for dessert).'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\":\"indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "\n",
    "Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from pypdf) (4.9.0)\n",
      "Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/284.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/284.0 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/284.0 kB 435.7 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/284.0 kB 326.8 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 112.6/284.0 kB 726.2 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 174.1/284.0 kB 876.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 276.5/284.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 284.0/284.0 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\poppo\\Desktop\\cheat sheets\\subscribes only notes\\DEEP LEARNING SPECIALIZATION-1.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x16e45d5f880>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 1 of 42 \\n DEEP LEARNING \\nSPECIALIZATION  \\n C O U R S E R A -D EE P L E A R N I N G. A I -A ND R E W  NG  \\nThese are notes taken from Deep Learning Specialization  by deeplearning.ai in Coursera . All \\nthe screenshots shown here are taken from the course videos. I would advise you to first \\nwatch the videos of the course in  order to completely understand the notes.  \\n \\nSKILLS YOU WILL GAIN  \\nTensorflow        Hyperparameter  \\nConvolutional  Neural  Network   Hyperparameter  Optimization  \\nArtificial  Neural  Network    Machine  Learning  \\nDeep  Learning      Inductive Transfer  \\nBackpropagation     Multi -Task Learning  \\nPython  Programming     Facial Recognition System  \\n \\nNEURON  \\n \\nIllustration of a neuron. Credit: David Baillot/ UC San Diego', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 0}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 2 of 42 \\n Neurons  are cells within the nervous system that transmit information \\nto other nerve cells, muscle, or gland cells. Most neurons have a cell \\nbody, an axon, and dendrites. The cell body contains the nucleus \\nand cytoplasm. The axon extends from the cell body and of ten \\ngives rise to many smaller branches before ending at nerve \\nterminals. Dendrites extend from the neuron cell body and receive \\nmessages from other neurons. Synapses are the contact points \\nwhere one neuron communicates with another. The dendrites are \\ncove red with synapses formed by the ends of axons from other \\nneurons.  \\n \\nhttps://www.xenonstack.com/images/blog/Artificial -Neural -Network -Architecture.jpg  \\nA neural  network  is a series of algorithms that recognize s the  \\nunderlying relationships in a set of data through a process that \\nmimics the way the human brain operates. In this sense, neural \\nnetworks refer to systems of neurons, either organic or artificial in \\nnature. Neural networks can adapt to changing input; so, the', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 1}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 3 of 42 \\n network generates the best possible result without needing to \\nredesign the output criteria.  \\n \\n \\n \\nCOURSE 1', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 2}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 4 of 42', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 3}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 5 of 42', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 4}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 6 of 42', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 5}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 7 of 42 \\n  \\n*Note : \\nThere are couple of optional videos in this course and I \\nwould suggest you guys to not skip it even if you don‚Äôt have \\ntime to watch because those videos helped me lot in \\nlearning deep learning better way. Also, the videos where \\nNg talks with Heroes of Deep  Learning would be a great \\ninspiration which is much needed after doing the difficult \\nassignments (Not at all difficult if you follow everything \\ncarefully).  \\nAnother advice is to derive all the formulas by yourself after \\nlearning from the course again even  if it takes a full day. \\nEven though Andrew Ng continuously says not to worry \\nabout the math I have found it very helpful to look in the \\ninternet about the math a little bit, just enough to \\nunderstand how the activation functions work. That way \\nyou would g et a better understanding of the notations used \\nin the course and how they are derived and would be able \\nto finish the assignments much faster.  Also try to re ‚Äì \\nimplement all the assignments at least once after \\nsubmitting.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 6}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 8 of 42 \\n  \\n \\n \\nWEEK 1 -INTRODUCTION  \\nWhat  is Neural Network?  \\nLet‚Äôs answer this question by taking an example of house \\nprice prediction. We have data set containing the size of \\nhouses and its price. We need to fit a line through this linear \\ndata that will allow us to predict future prices. What we  \\nnormally do is to fit a straight line through the data. But as \\nwe know that the straight line goes to the negative of y - \\naxis but the house prices cannot be negative so we bend \\nthe line near 0 on y -axis. \\n \\nThis is the simplest neural network we can implement. Line \\nthat we fit here is called a ReLU  (Rectified  Linear  Unit) \\nfunction which accepts input values and gives its max  (0,x). \\nWhich means if input value is positive it returns as it is. But if \\ninput is ne gative it returns 0.  \\nReLU  (Rectified  Linear  Unit)', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 7}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 9 of 42 \\n  \\nThe neuron accepts input which is size of the house \\uf0e0takes \\nmax of the size \\uf0e0outputs the price.  \\n \\n \\n \\n \\n \\nAs we have implemented the smallest neural network in \\norder to get a bigger neural network, we just put together \\nseveral of these smaller neural networks.  We would again \\nadd more features to our housing price prediction. Let‚Äôs  \\nconsider these simple neural networks which decides \\nfamily size, walkability and school quality.  \\n1. Size, # of bedrooms \\uf0e0 Family size  \\n2. Zip code (postal code) \\uf0e0Walkability  \\n3. Zip code, Wealth \\uf0e0Quality of school  \\nNow we would stack together all these to get a bigger \\nneural network that takes features Family size, Walkability \\nPRICE   SIZE  NEURON', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 8}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 10 of 42 \\n and Quality of school as input and give s price of house as \\noutput . \\n \\n \\n \\n                                                                                                      \\n                                                                                                                                                                                            \\n                                                                                  \\n                                                                   \\n \\nWhat we actually do here is we give the neural networks all the \\ninput features and let it decide which one leads to which output \\nfeature.  \\n \\n \\n                                                                                                                         \\n \\nSize \\n# of bedrooms  \\nZip code  \\nWealth  PRICE  \\nWALKABILITY  \\nHIDDEN UNITS', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 9}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 11 of 42 \\n Supervised Learning  \\nINPUT (X)  OUTPUT (Y)  APPLICATION  NN USED  \\nHome features  Price  Real estate  Standard \\nNN \\nAd, user info  Click on ad?  \\n(0/1)  Online \\nadvertising  Standard \\nNN \\nImage  Object \\n(1...1000)  Photo tagging  CNN  \\nAudio  Text transcript  Speech \\nrecognition  RNN  \\nEnglish  Chinese  Machine \\ntranslation  RNN  \\nImage, Radar \\ninfo Position of the \\ncars Autonomous \\ndriving  Hybrid  \\n \\nIn the example we saw of housing price prediction we use standard \\nneural networks. In image recognition we use Convolutional Neural \\nNetwork. In Text transcript and Machine translation we use \\nRecurrent Neural Network as the data is sequential data. And for \\nbigger application like autonomous driving we use a hybrid of \\nseveral of these neural networks.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 10}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 12 of 42 \\n Now we will see difference between structured and unstructured \\ndata . \\n \\nStructured data refers to well defined data which for example we \\ncan get from a database . Here the features have a well -defined \\nmeaning . Unstructured data refers to not well-defined  data like \\npictures, voice, text etc. Where the features do not have a very \\nwell-defined meaning.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 11}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 13 of 42 \\n WEEK 2 ‚Äì Logistic Regression  \\nBinary classification  \\nFor understanding binary classification let‚Äôs take an example of \\nclassifying an image as cat or no cat (1/0).  \\n \\nAn image is represented as a 3D matrix with its height, width and 3 \\ncolour channels. The 3 colour channels represent the pixel intensity \\nvalues of the respective colours in the image. For our input vector X \\nwe need to reshape this into a (H * W * 3, 1 ) vector which would be \\nour input X and Y (cat/ not cat) will be our output.  \\nThe algorithm for this problem is written as ùíöÃÇ=ùë∑(ùíö=ùüè|ùíô) where  ùíöÃÇ is \\nthe p robability that y = 1 given x. We have x as a (ùíè,ùíé) matrix with \\nparameters w and b where w is also an (ùíè,ùüè)  dimensional matrix. \\nGiven these parameters and x we need to find ùíöÃÇ. One  thing we can \\ndo is to fit a straight line i.e. ùíöÃÇ = ùíòùëªùíô+ùíÉ . But since this is a binary \\nclassification, we want the values to be between 0 and 1. So we \\ncan‚Äôt use this as ùíòùëªùíô+ùíÉ can be greater than 1 or even be -ve.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 12}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 14 of 42 \\n  \\nSo here we use another activation function called sigmoid  function \\nùíöÃÇ=ùùà(ùíõ) where ùíõ= ùíòùëªùíô+ùíÉ. The sigmoid function ùùà(ùíõ)= ùüè\\nùüè+‚Öá‚àíùíõ. \\nTherefor if the value of z is very high then ùíöÃÇ ùíäùíî ùíÑùíçùíêùíî‚Öá  ùíïùíê ùüè and if the \\nvalue of z is very low then ùíö ÃÇùíäùíî ùíÑùíçùíêùíî‚Öá  ùíïùíê ùüé. Now in order to re duce z \\nwe calculate loss function to know the difference of prediction and \\ntrue value.  \\nùë≥(ùíöÃÇ,ùíö)=‚àíùíöùíçùíêùíà ùíöÃÇ‚àí(ùüè‚àíùíö)ùíçùíêùíà(ùüè‚àíùíöÃÇ) \\n\\uf0b7 When y = 0 ùë≥(ùíöÃÇ,ùíö) = - ùíçùíêùíà(ùüè‚àíùíöÃÇ) i.e. loss would be less if ùíöÃÇ is \\nsmall i.e. close to 0.  \\n\\uf0b7 When y = 1 ùë≥(ùíöÃÇ,ùíö) = - ùíçùíêùíà(ùíöÃÇ) i.e. los s would be less if ùíöÃÇ is large \\ni.e. close to 1 . \\nFor m training example the cost function is written as:  \\n \\nIn order  to minimize the cost function, we need to do gradient \\ndescent. Let‚Äôs say we have only one parameter for the sake of \\nvisualising the cost function.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 13}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 15 of 42 \\n  \\nHere we need to reach the global minima. In order to do that we \\nneed to climb down the hill. If we are on the left side of the hill slope \\nis -ve, so gradient descent would be  ùíò=ùíò‚àí ùú∂(‚àí‚ÖÜùíò) = ùíò+ ùú∂(‚ÖÜùíò). \\ni.e. we are increasing value of w to reach bottom. If we are on the \\nright side of the loss function curve then slope is +ve so gradient \\ndescent is ùíò=ùíò‚àí ùú∂(‚ÖÜùíò) therefor we have to decrease w in order \\nto get to global minimum. When we have multiple features x1, x2 \\nwe have w1, w2 and b as parameters. We need to find dw1, dw2 \\nand db to do gradient descent as : \\nùíòùüè‚âîùíòùüè‚àíùú∂‚ÖÜùíòùüè \\nùíòùüê‚âîùíòùüê‚àíùú∂‚ÖÜùíòùüê \\nùíÉ‚âîùíÉ‚àíùú∂‚ÖÜùíÉ \\nThe two main process in preparing neural network model are \\nforward propagation to find loss and backward propagation to find \\nthe gradients.  \\nForward propagation', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 14}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 16 of 42 \\n  \\nThis the forward propagation to find loss. Now in order to find the \\ngradient descent we need to f ind the gradients dw and db. In order \\nto do that we use back propagation.  \\nBack propagation', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 15}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 17 of 42 \\n  \\nVectorization', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 16}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 18 of 42 \\n WEEK 3  Shallow Neural Network  \\n \\nhttps://www.druva.com/blog/understanding -neural -networks -through -visualization/  \\nLast, we ek we saw how to implement logistic regression in a neural \\nnetwork with input features X one neuron and output Y. This week \\nwe will see how to implement neural network with hidden layers.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 17}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 19 of 42 \\n  \\nAs shown in the picture the hidden layers are represented using [ ]  \\nbrackets. Instead of calculating one Z we now calculate more than \\none Z. First, we calculate Z1 using X, W1 and b and the activatio n \\nfunction a we get is used as input to the next layer to calculate Z2.  \\n \\nJust like we did forward propagation to compute loss function in \\nweek one here too we use forward propagation to cal culate  \\nùë≥(ùíÇ[ùüê],ùíö) and back propagation to calculate derivative s \\n‚ÖÜùíÇ[ùüê],‚ÖÜùíõ[ùüê],‚ÖÜùíò[ùüê],‚ÖÜùíÉ[ùüê],‚ÖÜùíÇ[ùüè],‚ÖÜùíõ[ùüè],‚ÖÜùíò[ùüè],‚ÖÜùíÉ[ùüè] \\n \\nThis neural network has three layers input layer ( ùíÇ[ùüé]), hidden layer \\n(ùíÇ[ùüè]) and output layer ( ùíÇ[ùüê]). In this neural network the hidden layer \\nhas 4 neurons which takes 3 input values from X and parameters \\nùíò[ùüè](ùüí,ùüë) and ùíÉ[ùüè](ùüí,ùüè) where 4 is the number of neurons in the \\nhidden layer, 3 is the number of input features. Each neuron gives \\noutput  ùíÇùüè[ùüè],ùíÇùüê[ùüè],ùíÇùüë[ùüè] ùíÇùíè‚ÖÜ  ùíÇùüí[ùüè] which is then passed to the output layer \\nwith parameters ùíò[ùüê](ùüè,ùüí) and ùíÉ[ùüê](ùüè,ùüè) where 1 is the number of', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 18}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 20 of 42 \\n output and 4 is the number of inputs. The output neuron gives \\noutput ùíÇùüè[ùüê] which is a scalar. This neural network is also called two -\\nlayer NN without considering the input layer.  \\nVectorization', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 19}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 21 of 42', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 20}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 22 of 42 \\n  \\nAll these examples are for single training sample', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 21}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 23 of 42 \\n Now we will see the implementation of neural network for multiple \\ntraining samples  \\n \\n \\n \\nWhen we include all the training samples (i) would represent the ith \\ntraining sample.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 22}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 24 of 42 \\n Vectorization  \\n \\nPlease note that the notation k  used here is just used for explaining this particular vectorization \\nand should not be used as the correct notation. We would see the right notation for the \\nnumber of nodes later in the course', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 23}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 25 of 42 \\n Now let‚Äôs talk about activation functions and decide which one is \\nbest to use . \\nActivation functions are generally represented as g (ùëß[ùëô]) where ùëô is \\nthe number of layers.  \\nSigmoid  (ùüè\\nùüè+‚Öá‚àíùíõ) \\n \\nBy Laughsinthestocks - Own work, CC BY -SA 4.0, https://commons.wikimedia.org/w/index.php?curid=44920533  \\n \\nSigmoid functions are functions which are shaped like s across y -\\naxis. This particular sigmoid function is the logistic function which \\nwhen given input values gives an output  between 0 and 1 . This i s \\nuseful when we want to predict probabilities and can be used in \\nthe last neuron in binary classification as an activation function. If \\nthe input value is very large and close t o ‚àû we get output as 1, if it \\nis very small and close  to ‚àí‚àû we get output as 0. In deep learning \\nwe generally do not use sigmoid function for the hidden layer \\nneurons as activation function because the slope of sigmoid \\nfunction is close zero as it starts to flatten out on both the ends and \\nmight affect the learning rate.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 24}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 26 of 42 \\n Derivativ e', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 25}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 27 of 42 \\n Hyperbolic Tangent  ( ‚Öáùíõ‚àí‚Öá‚àíùíõ\\n‚Öáùíõ+‚Öá‚àíùíõ) \\n \\n \\nBy Laughsinthestocks - Own work, CC BY -SA 4.0, https://commons.wikimedia.org/w/index.php?curid=44920568  \\n \\nHyperbolic tangent function is a sigmoid function with range \\nbetween -1 and 1 . It is superior function than sigmoid since it is \\ncentred at 0 rather than a t 0.5. Often, we use g (ùëß[ùëô]) = tanh as it \\ngives values between -1 and 1 whose mean is zero. The reason is \\nthat sometimes in a learning algorithm we centre the data. So, tanh \\nwill help in centring the data around 0 rather than around 0.5 which \\nwould help the next hidden layer  when pa ssed in as input. So, we \\ncan use different activation functions for different layers.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 26}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 28 of 42 \\n Derivative', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 27}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 29 of 42 \\n ReLU  \\n \\n \\nBy Laughsinthestocks - Own work, CC BY -SA 4.0, https://commons.wikimedia.org/w/index.php?curid=44920600  \\nThe Rectified  Linear  Unit is the most used activation function in the \\nworld right now. Since, it is used in almost all the convolutional \\nneural networks or deep learning.  As you can see, the ReLU is half \\nrectified (from bottom). f(z) is zero when z is less than zero and f(z) is \\nequal to z when z is above or equal to zero.  \\nRange:  [ 0 to infinity)  \\nThe function and its derivative  both are  monotonic . \\nBut the issue is that all the negative values become ze ro \\nimmediately which decreases the ability of the model to fit or train \\nfrom the data properly. That means any negative input given to the \\nReLU activation function turns the value into zero immediately in the \\ngraph, which in turns affects the resulting gra ph by not mapping \\nthe negative values appropriately.  The differential of ReLU lies \\nbetween 0 and 1.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 28}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 30 of 42 \\n  \\nLeaky ReLU  \\n \\nIt is an attempt to solve the dying ReLU problem  \\n \\nBy Laughsinthestocks at English Wikipedia - Transferred from en.wikipedia  to Commons., CC0, \\nhttps://commons.wikimedia.org/w/index.php?curid=46839644  \\nf(x) = ax. When x>0 a =1, x<0 a = 0.01  \\nThe leak helps to increase the range of the ReLU  function. Usually, \\nthe value of  a is 0.01 or so.  \\nWhen  a is not 0.01  then it is called  Randomized ReLU . \\nTherefore, the  range  of the Leaky ReLU is ( -‚àû to ‚àû). \\nBoth Leaky and Randomized ReLU functions are monotonic in \\nnature. Also, their derivatives also mono tonic in nature.   \\n \\nReLU is the activation function that we mostly use in deep learning.  \\n \\nhttps://towardsdatascience.com/activation -functions -neural -networks -1cbd9f8d91d6', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 29}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 31 of 42 \\n Derivative of ReLU and Leaky ReLU  \\nRecommend watching course video  to understand better  \\n \\n \\n \\n \\nwhy do we need a non -linear activation function ? \\nWithout the non -linear activation function the neural network \\nbehaves just like a linear regression function. The activation function \\ndoes the non -linear transformation to the input making it capable \\nto learn and perform more complex tasks.  without a non -linear \\nfunction doesn‚Äôt matter how many hidden layers we attach in the \\nneutral net all will behave in the same way. Neuron cannot learn \\nwith just a linear function attached to it; it requires a non -linear \\nactivation function to learn as per the difference w.r.t error.  So as \\nthe whole point of using a neural network is to get more features \\nout of the data which intern help in better prediction won‚Äôt be \\nserved if we use a linear function as activation function', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 30}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 32 of 42 \\n Gradient Descent  \\n \\nForward Propagation  \\n \\n \\nBack propagation  \\n \\n \\nFor one training sample  For m training samples', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 31}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 33 of 42 \\n Explanation  \\nPlease read the below notes carefully. These are important notes \\nfor doing program. Please consider watching videos before \\nreading this.  \\nDimensions  \\n \\n \\n \\n \\n \\n \\n \\n \\nNow we will see how to calculate the backpropagation for gradient \\ndescent', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 32}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 34 of 42', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 33}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 35 of 42 \\n  \\n \\nRandom Initiali sation  \\n \\nIf we initialise  the parameters as zero  or matrix of zeros then we \\nwould end up calculating the same activation function  for each \\nnode different layers. The whole point of introducing hidden units is', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 34}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 36 of 42 \\n to get new features to the data, so if the features  we get are all \\nsame  in all nodes in a layer then that won‚Äôt serve the purpose. So, \\nwe use random numbers to initialize the p arameters so that each \\nweight is different for different features so that the new features that \\nwe get from the nodes won‚Äôt be equal to each other as shown in \\nfigure above.  \\nIf we multiply the randomly generated number by 100 rather than \\n0.01 then we would  end up calculating a large value for Z and if \\nour activation function is tanh or any sigmoid function then for large \\nz we would end up at the flat part of the function where the slope \\nwould be close to zero so learning process would be really slow.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 35}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 37 of 42 \\n WEEK 4  Deep Neural Network  \\n \\n \\nhttps://www.druva.com/blog/understanding -neural -networks -through -visualization/', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 36}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 38 of 42 \\n A deep NN is an NN with more than two or more hidden layer. Deep \\nneural networks can learn some functions that shallower NN can‚Äôt.  \\n \\n \\nùëç[ùëô]= ùëä[ùëô]ùê¥[ùëô‚àí1]+ùëè[ùëô]  \\nùê¥[ùëô]= ùëî[ùëô](ùëç[ùëô]) \\uf0e0 Activation matrix of layer l  \\nùëä[ùëô],ùëè[ùëô] \\uf0e0 Parameters  for layer l  \\nùëõ[ùëô] \\uf0e0 Number of hidden units in layer l  \\n \\nWhy we use Deep Neural Networks?  \\n \\nIn this example we have given images as input to the neural \\nnetwork. The first layer might detect features like different kinds of', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 37}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 39 of 42 \\n edges, the second layer might detect features like nose, eyes, etc. \\nthe third layer might detect  features like different faces. So, by \\nhaving more than one layer we are able to get more useful features \\nform the images.  \\nBuilding blocks of NN  \\n \\nIn forward propagation we input ùê¥[ùëô‚àí1] with parameters ùëä[ùëô] and \\nùëè[ùëô] and gets output ùê¥[ùëô] also we store ùëç[ùëô] in cache to be used for \\nbackpropagation. We continue this till we get ùê¥[ùêø] which is equal to \\nùë¶ÃÇ. In backward propagation we give ùëëùê¥[ùëô] with ùëä[ùëô] and ùëè[ùëô] and \\ngets ùëëùê¥[ùëô‚àí1] as output and we calculate ùëëùëä[ùëô] and ùëëùëè[ùëô]. \\n \\nForward Propagation  \\nFor ùíç = 1 to L:  \\n ùëç[ùëô]= ùëä[ùëô]ùê¥[ùëô‚àí1]+ùëè[ùëô]  \\nùê¥[ùëô]= ùëî[ùëô](ùëç[ùëô])  \\nùíöÃÇ=ùë®ùë≥', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 38}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 40 of 42 \\n Back Propagation  \\nFor ùíç = L to 1:  \\n \\n \\n*Note  \\nFor ùëô  = L,  ùëëùê¥[ùëô]=‚ÖÜùêø\\n‚ÖÜùê¥[ùêø] = ‚àíùë¶\\nùëé‚àí1‚àíùë¶\\n1‚àíùëé if we are using sigmoid as output \\nactivation function and there is no ùëëùëç[ùëô+1] to calculate.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 39}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 41 of 42 \\n To generalize:  \\n \\n \\nPara meters v/s Hyperparameters  \\nParameters  \\n \\nHyperparameters  \\nLearning rate ùú∂ \\uf0e0 Decides the rate at which gradients the \\nparameters change.  \\nNo of iterations \\uf0e0 Decides no of times gradient descent Is done to \\nadjust the parameters.  \\nNo of hidden layers ùíç \\uf0e0 Decides the number of variety of features.  \\nNo of hidden units ùíè[ùíç] \\uf0e0 Decides the number of activation units.', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 40}),\n",
       " Document(page_content='Deep Learning Specialization Notes ‚Äì By Deepak Jose  \\nPage 42 of 42 \\n Choice of activation function \\uf0e0 Decides the nature of features \\nproduced in the NN units.  \\nAll the hyperparameters are tuned  to decide which ones are best \\nto get the best results. It‚Äôs very rare to have knowledge of the best \\nvalue for all these parameters in advance. So, the best way to know \\nis to do multiple trial and error steps and find out which ones \\nminimizes the cost v/s iteration curve faster and perfectly. We can \\nalso check for accuracy score.  \\n \\n \\n \\n \\n \\n \\n \\n-------------- üòä---------------', metadata={'source': 'C:\\\\Users\\\\poppo\\\\Desktop\\\\cheat sheets\\\\subscribes only notes\\\\DEEP LEARNING SPECIALIZATION-1.pdf', 'page': 41})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
