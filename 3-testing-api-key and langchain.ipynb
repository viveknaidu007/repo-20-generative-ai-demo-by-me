{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is OpenAI API?\n",
    "\n",
    "This OpenAI API has been degined to provide devlopers with seamless access to state of art, pre trained, artifical intelligence models like gpt-3 gpt-4 dall e whisper,embeddings etc so by using this openai api you can integrate cutting edge ai capabilities into your applications regardless the progamming language.\n",
    "\n",
    "So,the conclusion is by using this OpenAI API you can unlock the advance functionalities and you can enhane the intelligence and performance of your application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generatate OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generatate open api key\n",
    "\n",
    "mykey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=mykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                created           object  \\\n",
       "0            (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "1        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
       "2                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "3                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "4        (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "5                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "6                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "7                   (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "8                   (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "9        (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
       "10                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "11           (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "12       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "13                    (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "14           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "15                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "16       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "17                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "18  (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "19            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "\n",
       "                       owned by  \n",
       "0            (owned_by, openai)  \n",
       "1            (owned_by, system)  \n",
       "2            (owned_by, system)  \n",
       "3            (owned_by, system)  \n",
       "4   (owned_by, openai-internal)  \n",
       "5            (owned_by, system)  \n",
       "6            (owned_by, system)  \n",
       "7            (owned_by, system)  \n",
       "8            (owned_by, system)  \n",
       "9            (owned_by, system)  \n",
       "10           (owned_by, openai)  \n",
       "11           (owned_by, openai)  \n",
       "12           (owned_by, openai)  \n",
       "13  (owned_by, openai-internal)  \n",
       "14           (owned_by, system)  \n",
       "15           (owned_by, system)  \n",
       "16           (owned_by, system)  \n",
       "17  (owned_by, openai-internal)  \n",
       "18           (owned_by, system)  \n",
       "19  (owned_by, openai-internal)  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(all_models), columns = [\"id\", \"created\", \"object\", \"owned by\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OpenAI Playground\n",
    "\n",
    "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
    "\n",
    "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
    "\n",
    "3. In chat there is option of **system**: So the meaning is how the chatbot should behave\n",
    "\n",
    "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
    "\n",
    "Here is a question: How to make a money so quickly?\n",
    "\n",
    "**Model**\n",
    "\n",
    "**Temperature**\n",
    "\n",
    "**Maximum Length**\n",
    "\n",
    "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.**\n",
    "\n",
    "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, “Hey, don't repeat words too much.”**\n",
    "\n",
    "**The OpenAI Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.**\n",
    "\n",
    "\n",
    "**Now come to assistant one**\n",
    "\n",
    "**Retrieval-augmented generation (RAG):**  is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
    "\n",
    "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of tasks by executing Python code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Chat Completion API and Function Calling\n",
    "\n",
    "**openai.Completion.create()**: This method is used to generate completions or responses. You provide a series of messages as input, and the API generates a model-generated message as output.\n",
    "\n",
    "**openai.ChatCompletion.create() :** Similar to Completion.create(), but specifically designed for chat-based language models. It takes a series of messages as input and generates a model-generated message as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\" : \"who is pawankalyan\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=10,\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8n2ZIs5zZ3MCdFHlfwKJZFveje0iB', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Pawan Kalyan is an Indian actor,', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='Pawan Kalyan is an Indian actor,', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=2, logprobs=None, message=ChatCompletionMessage(content='Pawan Kalyan is an Indian actor,', role='assistant', function_call=None, tool_calls=None))], created=1706698636, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=30, prompt_tokens=13, total_tokens=43))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pawan Kalyan is an Indian actor,'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'\\nmodel = \"\"\\nprompt = input prompt\\nmax_tokens = in how many number of tokens you want result\\ntemperature = for getting some crative output\\nn = number of the output\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let try to understnd the different paramaneters inside the methods\n",
    "''''\n",
    "model = \"\"\n",
    "prompt = input prompt\n",
    "max_tokens = in how many number of tokens you want result\n",
    "temperature = for getting some crative output\n",
    "n = number of the output\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2521649297.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[62], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://openai.com/pricing\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#for pricing\n",
    "#https://openai.com/pricing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for seeing the tokens in our output\n",
    "#https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#prompts are collections of tokens , tokens means just a words collection of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mykey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"vivek naidu is a student of computer science at IIT hyderabad. He is an indian and has a 9.1 GPA. vivek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vivek naidu is a student of computer science at IIT hyderabad. He is an indian and has a 9.1 GPA. vivek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x1bae5b29160>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\n",
    "\n",
    "        \"role\":\"user\",\n",
    "        \"content\":prompt\n",
    "    }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8n2a9H7gZo15rdDeQyHnOrlgjMmsq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"vivek naidu\",\\n  \"college\": \"IIT hyderabad\",\\n  \"grades\": \"9.1 GPA\",\\n  \"club\": \"college\\'s AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1706698689, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=43, prompt_tokens=107, total_tokens=150))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'vivek naidu',\n",
       " 'college': 'IIT hyderabad',\n",
       " 'grades': '9.1 GPA',\n",
       " 'club': \"college's AI Club\"}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function calling\n",
    "#below code is refernce taken from openai website in funcrion calling tab\n",
    "#its not function like python ok.\n",
    "#we are passing this below function to chatpt api\n",
    "\n",
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "    functions = student_custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"name\": \"vivek naidu\",\\n  \"college\": \"IIT hyderabad\",\\n  \"grades\": 9.1,\\n  \"club\": \"AI Club\"\\n}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will get output as given information as a output in custom fucntion\n",
    "response2\n",
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"vivek naidu\",\\n  \"college\": \"IIT hyderabad\",\\n  \"grades\": 9.1,\\n  \"club\": \"AI Club\"\\n}'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here output is not looking good\n",
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'vivek naidu',\n",
       " 'college': 'IIT hyderabad',\n",
       " 'grades': 9.1,\n",
       " 'club': 'AI Club'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here looking good by usinf json\n",
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(response2.choices[0].message.function_call.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"vivek naidu is a student of computer science at IIT hyderabad. He is an indian and has a 9.1 GPA. vivek is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_two = \"teja is a student of computer science at IIT mumbai. He is an indian and has a 8.0 GPA. teja is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_three = \"honey is a student of computer science at IIT madras. she is an indian and has a 9.5 GPA. honey is known for her programming skills and is an active member of the college's AI Club. she hopes to pursue a career in artificial intelligence after graduating.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'vivek naidu', 'college': 'IIT hyderabad', 'grades': 9.1, 'club': 'AI Club'}\n",
      "{'name': 'teja', 'college': 'IIT Mumbai', 'grades': 8.0, 'club': 'AI Club'}\n",
      "{'name': 'honey', 'college': 'IIT madras', 'grades': 9.5, 'club': 'AI Club'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "student_info = [student_description, student_two,student_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = student_custom_function,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funtion_two=student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [student_custom_function[0], function_two[0]]\n",
    "student_info = [student_description, student_description_two,student_description_three]\n",
    "for student in student_info:\n",
    "    response =  client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [{'role': 'user', 'content': student}],\n",
    "        functions = functions,\n",
    "        function_call = 'auto'\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and actually we didnt find a difference between direct call and fucntion call\n",
    "\n",
    "#now i will show advance example we can find between "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#advance example of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "#generatate open api key\n",
    "\n",
    "\n",
    "mykey = \"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\"\n",
    "\n",
    "#openai.api_key = mykey\n",
    "client = OpenAI(api_key=mykey) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im asking my llm model:\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages =  [\n",
    "        {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"when's the next flight from delhi to chennai?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI, I don't have access to real-time flight schedules. It is best to check with your preferred airline or visit a flight booking website or app for the most up-to-date information regarding flights from Delhi to Chennai.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure airport, e.g. DEL\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. MUM\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"when the next flight from new delhi to chennai\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":user_prompt\n",
    "        }\n",
    "    ],\n",
    "    #add function calling\n",
    "    functions = function_descriptions,\n",
    "    function_call = \"auto\" #specify the fucntion call\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignent\n",
    "#this my api not real its virtual\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"Get flight information between two locations.\"\"\"\n",
    "\n",
    "    # Example output returned from an API or database\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"airline\": \"KLM\",\n",
    "        \"flight\": \"KL643\",\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'DEL', 'loc_destination': 'MAA'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEL'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAA'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments).get('loc_destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(response2.choices[0].message.function_call.arguments).get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_flight_info(loc_origin, loc_destination)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function=eval(response2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"DEL\", \"loc_destination\": \"MAA\", \"datetime\": \"2024-02-01 17:01:59.701258\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "flight = chosen_function(**params)\n",
    "\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when the next flight from new delhi to chennai'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " response2.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\": \"DEL\", \"loc_destination\": \"MAA\", \"datetime\": \"2024-02-01 17:01:59.701258\", \"airline\": \"KLM\", \"flight\": \"KL643\"}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\",\"content\": user_prompt},\n",
    "    {\"role\": \"function\", \"name\": response2.choices[0].message.function_call.name, \"content\": flight}\n",
    "      ],\n",
    "    # Add function calling\n",
    "    functions=function_descriptions,\n",
    "    function_call=\"auto\",  # specify the function call\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8nNj1a46YIGOJ7LxXkizbwK3n4u6S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from New Delhi (DEL) to Chennai (MAA) is on February 1, 2024. The flight is operated by KLM and the flight number is KL643. The departure time is 17:01:59.', role='assistant', function_call=None, tool_calls=None))], created=1706779963, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=52, prompt_tokens=141, total_tokens=193))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from New Delhi (DEL) to Chennai (MAA) is on February 1, 2024. The flight is operated by KLM and the flight number is KL643. The departure time is 17:01:59.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funtion Calling\n",
    "\n",
    "Learn how to connect large language models to external tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (0.0.284)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in langchain w ehave different different modules in that we have different different modules\n",
    "\n",
    "\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.4\n"
     ]
    }
   ],
   "source": [
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (0.0.284)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (0.0.15)\n",
      "Collecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
      "  Downloading langchain_core-0.1.17-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
      "   ---------------------------------------- 0.0/803.6 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/803.6 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/803.6 kB 393.8 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 92.2/803.6 kB 655.4 kB/s eta 0:00:02\n",
      "   ------- ------------------------------ 153.6/803.6 kB 833.5 kB/s eta 0:00:01\n",
      "   -------------- ------------------------- 286.7/803.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 460.8/803.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 614.4/803.6 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 803.6/803.6 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 235.9/235.9 kB 7.3 MB/s eta 0:00:00\n",
      "Installing collected packages: langchain-core, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.15\n",
      "    Uninstalling langchain-core-0.1.15:\n",
      "      Successfully uninstalled langchain-core-0.1.15\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.284\n",
      "    Uninstalling langchain-0.0.284:\n",
      "      Successfully uninstalled langchain-0.0.284\n",
      "Successfully installed langchain-0.1.4 langchain-core-0.1.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#for updating packages\n",
    "#pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whatever we request it will hit in opneai\n",
    "#langchain is a opensource and it is very powerfull\n",
    "#\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poppo\\anaconda3\\envs\\mlproj\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "mykey = \"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\"\n",
    "client = OpenAI(openai_api_key=mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero shot prompting\n",
    "prompt = \"can u tell me total no of country in asia?, can you give me the top10 country name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThere are 48 countries in Asia. \\n\\nThe top 10 countries in Asia, based on population, are:\\n\\n1. China\\n2. India\\n3. Indonesia\\n4. Pakistan\\n5. Bangladesh\\n6. Japan\\n7. Philippines\\n8. Vietnam\\n9. Iran\\n10. Turkey'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in asia\n",
      "\n",
      "There are currently 48 countries in Asia. \n",
      "\n",
      "The top 10 countries in Asia by population are: \n",
      "\n",
      "1. China \n",
      "2. India \n",
      "3. Indonesia \n",
      "4. Pakistan \n",
      "5. Bangladesh \n",
      "6. Japan \n",
      "7. Philippines \n",
      "8. Vietnam \n",
      "9. Iran \n",
      "10. Turkey\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(prompt).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next topic will be\n",
    "\n",
    "#hugging face api with langchain\n",
    "\n",
    "#use of the langchain in very detailed way\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
